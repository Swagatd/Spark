# Spark
Pyspark

This is the code repository for PySpark,It contains project files Jupyter notebooks while learning pyspark.

Apache Spark is an open source framework for efficient cluster computing with a strong interface for data parallelism and fault tolerance. 
I have tested on python3.5+ and spark 2.2 version on my ubuntu system.

You will get familiar with the modules available in PySpark. You will learn how to abstract data with RDDs and DataFrames and understand the streaming capabilities of PySpark. Also, you will get a thorough overview of machine learning capabilities of PySpark using ML and MLlib, graph processing using GraphFrames, and polyglot persistence using Blaze.
