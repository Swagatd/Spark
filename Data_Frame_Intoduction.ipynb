{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Frame Intoduction.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "e0ifokqW0Oe-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###What are Dataframes:\n",
        "\n",
        "Dataframes generally refers to a data structure, which is tabular in nature. It represents Rows, each of which consists of a number of observations. \n",
        "\n",
        "####Why do we need Dataframes\n",
        "\n",
        "(1)  Dataframes are designed to process a large collection of **structured as well as Semi-Structured data.** Observations in Spark DataFrame are organized under named columns, which helps Apache Spark to understand the schema of a DataFrame. This helps Spark optimize execution plan on these queries. It can also handle Petabytes of data.\n",
        "\n",
        "(2)  Data frame APIs usually supports elaborate methods for **slicing-and-dicing **the data. It includes operations such as “selecting” rows, columns, and cells by name or by number,  filtering out rows, etc. Statistical data is usually very messy and contain lots of missing and wrong values and range violations. So a critically important feature of data frames is the explicit management of missing data."
      ]
    },
    {
      "metadata": {
        "id": "5zaKv2wF1ODp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataframe Creation in Pyspark\n",
        "\n",
        "A DataFrame in Apache Spark can be created in multiple ways:\n",
        "\n",
        "(1)  It can be created using different data formats. For example, loading the data from JSON, CSV.\n",
        "\n",
        "(2)  Loading data from Existing RDD."
      ]
    },
    {
      "metadata": {
        "id": "uiBYkelK4WtY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aa0211a-b33a-494c-99fe-662a15431329",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532614292535,
          "user_tz": -330,
          "elapsed": 1570,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#spark session\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "  .master(\"local\") \\\n",
        "  .appName(\"df create\") \\\n",
        "  .getOrCreate()\n",
        "\n",
        "\n",
        "from pyspark.sql import *\n",
        " \n",
        "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
        " \n",
        "employee1 = Employee('aman', 'sharma', 'aman@gmail.co', 100000)\n",
        "employee2 = Employee('kanak', 'rai', 'kanak@gmail.edu', 120000 )\n",
        "employee3 = Employee('vinod', None, 'vinod@gmail.edu', 140000 )\n",
        "employee4 = Employee('rani', 'arora', 'rani@gmail.co', 160000 )\n",
        "employee5 = Employee('punit', 'singh', 'punit@gmail.co', 160000 )\n",
        " \n",
        "print(employee3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row(firstName='vinod', lastName=None, email='vinod@gmail.edu', salary=140000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zdi5PHoN5Xj8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "83a5fe46-0285-48f3-a74e-3b169f36bc1b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532614316620,
          "user_tz": -330,
          "elapsed": 5274,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create department DF\n",
        "\n",
        "department1 = Row(id='123456', name='HR')\n",
        "department2 = Row(id='789012', name='OPS')\n",
        "department3 = Row(id='345678', name='FN')\n",
        "department4 = Row(id='901234', name='DEV')\n",
        "\n",
        "# create department with employee\n",
        "\n",
        "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2, employee5])\n",
        "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
        "departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee3])\n",
        "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n",
        "\n",
        "\n",
        "#create Dataframe from the list of Rows\n",
        "\n",
        "departmentsWithEmployees_Seq = [departmentWithEmployees1, departmentWithEmployees2]\n",
        "dframe = spark.createDataFrame(departmentsWithEmployees_Seq)\n",
        "display(dframe)\n",
        "dframe.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[department: struct<id:string,name:string>, employees: array<struct<firstName:string,lastName:string,email:string,salary:bigint>>]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+------------+--------------------+\n",
            "|  department|           employees|\n",
            "+------------+--------------------+\n",
            "| [123456,HR]|[[aman,sharma,ama...|\n",
            "|[789012,OPS]|[[vinod,null,vino...|\n",
            "+------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ExsiuM828E4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reading Data from CSV file\n",
        "\n",
        "Here we are going to use the spark.read.csv method to load the data into a dataframe emp_df"
      ]
    },
    {
      "metadata": {
        "id": "oBJ9lI3g-ODK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "41eea40d-cb53-4071-d20e-17e5356d9361",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615072624,
          "user_tz": -330,
          "elapsed": 2539,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df = spark.read.csv(\"/content/emp.csv\", inferSchema = True, header = True)\n",
        " \n",
        "emp_df.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---+---+-----+\n",
            "|  name|age|sex|marks|\n",
            "+------+---+---+-----+\n",
            "|  amar| 24|  m|   34|\n",
            "|mahesh| 25|  m|   36|\n",
            "| gitah| 23|  f|   31|\n",
            "|  ritu| 24|  f|   30|\n",
            "|  aman| 25|  m|   32|\n",
            "| nilam| 26|  f|   37|\n",
            "+------+---+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai_iEu5t-t6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Column Names and Count (Rows and Column)\n",
        "\n",
        "When we want to have a look at the names and a count of the number of Rows and Columns of a particular Dataframe, we use the following methods."
      ]
    },
    {
      "metadata": {
        "id": "lLrFQk3t--1G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f9cc4d8-e111-4c63-b7b3-672d9512e48f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615230360,
          "user_tz": -330,
          "elapsed": 1270,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df.columns #Column Names\n",
        " \n",
        "emp_df.count() #Row Count\n",
        " \n",
        "len(emp_df.columns) #Column Count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "xUBkkZwu_Z7-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we want to have a look at the summary of any particular column of a Dataframe, we use the describe method. This method gives us the statistical summary of the given column"
      ]
    },
    {
      "metadata": {
        "id": "kug7xyIU_b6f",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cbb10750-e0a6-49d8-96ab-50fa061a272a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615381961,
          "user_tz": -330,
          "elapsed": 1004,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df.describe('marks').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|             marks|\n",
            "+-------+------------------+\n",
            "|  count|                 6|\n",
            "|   mean|33.333333333333336|\n",
            "| stddev|2.8047578623950162|\n",
            "|    min|                30|\n",
            "|    max|                37|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PxO4cQmU_nuW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df.describe('name').show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxfVgWQJ_4An",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8cbdd9d-4a3f-4e3e-8d53-8fa916b72628",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615449932,
          "user_tz": -330,
          "elapsed": 1004,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df.select('name','age').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|  amar| 24|\n",
            "|mahesh| 25|\n",
            "| gitah| 23|\n",
            "|  ritu| 24|\n",
            "|  aman| 25|\n",
            "| nilam| 26|\n",
            "+------+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w0O8x5D-AGqr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "536a4222-520d-4d47-c377-158b46fd2c0d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615544825,
          "user_tz": -330,
          "elapsed": 1103,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Filtering Data\n",
        "\n",
        "# where age = 24\n",
        "emp_df.filter(emp_df.age=='24').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+---+---+-----+\n",
            "|name|age|sex|marks|\n",
            "+----+---+---+-----+\n",
            "|amar| 24|  m|   34|\n",
            "|ritu| 24|  f|   30|\n",
            "+----+---+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bicGZV24AiUS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9ecc392d-06b7-4ca2-cc71-97eeec7917aa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615616320,
          "user_tz": -330,
          "elapsed": 1223,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emp_df.orderBy(emp_df.age).show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---+---+-----+\n",
            "|  name|age|sex|marks|\n",
            "+------+---+---+-----+\n",
            "| gitah| 23|  f|   31|\n",
            "|  amar| 24|  m|   34|\n",
            "|  ritu| 24|  f|   30|\n",
            "|  aman| 25|  m|   32|\n",
            "|mahesh| 25|  m|   36|\n",
            "| nilam| 26|  f|   37|\n",
            "+------+---+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qhBYLLjbA9Bs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Performing SQL Queries\n",
        "\n",
        "\n",
        "We can also pass SQL queries directly to any dataframe, for that we need to \n",
        "create a table from the dataframe using the registerTempTable method and then\n",
        "use the sqlContext.sql() to pass the SQL queries. "
      ]
    },
    {
      "metadata": {
        "id": "oH1q9THCBAnF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d3f07e5-e390-48d7-faaa-94e728660b85",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615854814,
          "user_tz": -330,
          "elapsed": 986,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "sqlContext = SQLContext (sc)\n",
        "\n",
        "emp_df.registerTempTable('emp_table')\n",
        " \n",
        "sqlContext.sql('select * from emp_table').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---+---+-----+\n",
            "|  name|age|sex|marks|\n",
            "+------+---+---+-----+\n",
            "|  amar| 24|  m|   34|\n",
            "|mahesh| 25|  m|   36|\n",
            "| gitah| 23|  f|   31|\n",
            "|  ritu| 24|  f|   30|\n",
            "|  aman| 25|  m|   32|\n",
            "| nilam| 26|  f|   37|\n",
            "+------+---+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gHXRAa5UBmHM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dbd52949-0783-4bfb-e25f-ce3cb294db18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532615895255,
          "user_tz": -330,
          "elapsed": 1274,
          "user": {
            "displayName": "Amresh Sharma",
            "photoUrl": "//lh6.googleusercontent.com/-8WMhDUear_U/AAAAAAAAAAI/AAAAAAAAACA/JZvOowVPq-8/s50-c-k-no/photo.jpg",
            "userId": "103341888517734224992"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sqlContext.sql('select * from emp_table where age = 26').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+---+-----+\n",
            "| name|age|sex|marks|\n",
            "+-----+---+---+-----+\n",
            "|nilam| 26|  f|   37|\n",
            "+-----+---+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwJpO8OwB1KQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As shown in previous example you can run  sql select query on dataframe. experiment and practice with sql and dataframe to learn more.\n",
        "\n",
        "**Happy learning!**"
      ]
    }
  ]
}